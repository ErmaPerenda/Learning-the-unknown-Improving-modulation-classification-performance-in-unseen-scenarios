# Learning-the-unknown-Improving-modulation-classification-performance-in-unseen-scenarios
The tflearn code for INFOCOM 2021 paper: Learning the unknown: Improving modulation classification performance in unseen scenarios

Dataset used in this code is generated by using code given in repo https://github.com/ErmaPerenda/Modulation-dataset-generation-in-MATLAB.

The proposed STN-ResNeXt is given in Fig. 1. The instances of size 1024 are fed into the model. The model has two parallel branches: 

(1) ClassNet learns features from the original input; 

(2) STN+ClassNet learns features from the transformed input.

Both learned features are concatenated and sent to the Dense layer of 128 units, followed by the Softmax layer. STN consists of three modules: (1) the Localizer predicts transformation matrix; (2) the Grid Generator implements the transformation; (3) the Sampler implements interpolation. The Localizer network contains two CNN layers followed
by three ResNeXt blocks (shown in Fig. 11) and a Global Average Pooling layer. The last layer in the Localizer is a dense layer with 6 units, whose weights are initialized as [0:7;-0:7; 0:1; 0:3; 0:7; 0:2]. ClassNet consists of two CNN layers, six ResNeXt blocks, and a Global Average Pooling Layer. Note that ClassNet and the Localizer hyperparameters (number of ResNeXt blocks, block structure, etc.) are optimized through trial-and-error, and found optimal values are given in Figs. 1 and 2.

![image](https://user-images.githubusercontent.com/10497981/227714416-3464bac8-efac-438e-b30e-a41e7ddc5add.png)
Fig 1: STN-ResNeXt network layout.

![image](https://user-images.githubusercontent.com/10497981/227714428-78a3cad0-13c9-4a45-b2ac-8199c56307b8.png)
Fig 2: ResNeXt block layout.

